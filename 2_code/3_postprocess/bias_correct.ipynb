{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045de6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydromt_sfincs import SfincsModel, utils\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import hydromt\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e9a7d8",
   "metadata": {},
   "source": [
    "## bias correct flood depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdir = r\"../../3_models/sfincs\"\n",
    "rdir = r\"../../4_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc2de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(join(rdir, 'hmax.zarr')).swap_dims({'index':'scen'})\n",
    "da = ds['hmax'].fillna(0)\n",
    "da.attrs.update(_FillValue=da.attrs['nodatavals'][0])\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503d43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod0 = SfincsModel(join(mdir, '00_base_riv'), mode='r')\n",
    "rivmsk = mod0.staticmaps['rivmsk'].raster.flipud()==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias correct for Q and H but make sure to keep P\n",
    "nodata = da.attrs['_FillValue']\n",
    "# get Q2 + MSHW map for bias correction\n",
    "bias, da0 = 'q2', da.sel(scen=['qb002_qp002_h000_p000']).squeeze(drop=True)\n",
    "mask = np.logical_and(da0!=nodata, ~rivmsk)\n",
    "# account for minimal P in all scenarios\n",
    "pscen = [f'qb000_qp000_h000_p{s[-3:]}' for s in da.scen.values]\n",
    "dap = da.sel(scen=pscen).reset_coords(drop=True).drop('scen')\n",
    "dap = np.maximum(0, dap - da.sel(scen=['qb000_qp000_h000_p000']).squeeze(drop=True))\n",
    "# take maximum of pscen and bias corrected scens\n",
    "da1 = np.maximum(dap, da-da0).where(mask, 0)\n",
    "# da1.attrs.update(**da.attrs)\n",
    "# da1 = da1.chunk({'x':-1, 'y':-1, 'scen':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819dd89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_out = xr.merge([ds.drop_vars('hmax'), da1]).swap_dims({'scen': 'index'})\n",
    "ds_out = da1.to_dataset().swap_dims({'scen': 'index'})\n",
    "ds_out.attrs = {}\n",
    "ds_out.chunk({'index':50, 'x':250, 'y':250}).drop(['spatial_ref', 'band']).to_zarr(join(rdir, 'hmax_bias_corrected.zarr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bias corrected floodmaps\n",
    "for rp in  np.array([0,2,5,10,50,100,500], dtype=int):\n",
    "    scens = [\n",
    "        f'qb{rp:03d}_qp000_h000_p000', \n",
    "        f'qb000_qp{rp:03d}_h000_p000', \n",
    "        f'qb000_qp000_h{rp:03d}_p000', \n",
    "        f'qb000_qp000_h000_p{rp:03d}', \n",
    "        f'qb{rp:03d}_qp{rp:03d}_h{rp:03d}_p{rp:03d}'\n",
    "    ]\n",
    "    for scen in scens:\n",
    "        da_scen = da1.sel(scen=scen)\n",
    "        fn_out = join(rdir, 'hmax', f'{scen}.tif')\n",
    "        da_scen.raster.flipud().raster.to_raster(fn_out, compress='lzw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f66da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
