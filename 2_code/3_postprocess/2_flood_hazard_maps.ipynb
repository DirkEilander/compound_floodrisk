{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045de6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import hydromt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94124cce",
   "metadata": {},
   "source": [
    "## read flood data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdir = r\"../../3_models/sfincs\"\n",
    "rdir = r\"../../4_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = ['h_rp','p_rp','qb_rp','qp_rp']\n",
    "ds = xr.open_zarr(join(rdir, 'hmax.zarr'))#.swap_dims({'index':'scen'}).set_coords(index_cols)\n",
    "da1 = ds['hmax']\n",
    "nodata = da1.raster.nodata\n",
    "print(nodata)\n",
    "da1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80f6be6",
   "metadata": {},
   "source": [
    "## Univariate and full dependence / indepence scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6ea8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bias corrected floodmaps\n",
    "for rp in  np.array([2,5,10,25,50,100,250,500], dtype=int):\n",
    "    scens = {\n",
    "        f'qb{rp:03d}_qp000_h000_p000': f'qb_rp{rp:03d}', \n",
    "        f'qb000_qp{rp:03d}_h000_p000': f'qp_rp{rp:03d}', \n",
    "        f'qb000_qp000_h{rp:03d}_p000': f'h_rp{rp:03d}', \n",
    "        f'qb000_qp000_h000_p{rp:03d}': f'p_rp{rp:03d}', \n",
    "        f'qb{rp:03d}_qp{rp:03d}_h{rp:03d}_p{rp:03d}': f'compound_fulldep_rp{rp:03d}'\n",
    "    }\n",
    "    ds_scens = xr.merge([da1.sel(scen=scen).rename(name).reset_coords(drop=True) for scen, name in scens.items()])\n",
    "    ds_scens[f'compound_indep_rp{rp:03d}'] = da1.sel(scen=list(scens.keys())[:-1]).max('scen')\n",
    "    ds_scens.raster.set_crs(da1.raster.crs)\n",
    "    for dvar in ds_scens.data_vars.keys():\n",
    "        ds_scens[dvar].raster.set_nodata(da1.raster.nodata)\n",
    "    ds_scens.raster.flipud().raster.to_mapstack(join(rdir, 'hmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd0e4e",
   "metadata": {},
   "source": [
    "## Calculate compound comound flood depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8bbbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sample = pd.read_csv(join(rdir, r'sim_EVENTS_rp.csv'), index_col=0).rename(columns={'h_tsw_rp': 'h_rp', 'h_tsw': 'h'})\n",
    "\n",
    "\n",
    "df_flood = da1.reset_coords().drop(['band', 'spatial_ref', 'x', 'y', 'hmax'], errors='ignore').to_dataframe()\n",
    "# df_flood[index_cols] = np.maximum(1, df_flood[index_cols])\n",
    "ds_flood_rp = df_flood.reset_index().drop(columns=index_cols).set_index(\n",
    "    pd.MultiIndex.from_frame(df_flood[index_cols])\n",
    ").to_xarray()\n",
    "ds_flood_rp['index'] = ds_flood_rp['index'].fillna(-1).astype(int)\n",
    "ds_flood_rp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nearest scen for each sample based on rp\n",
    "# TODO: should this be based on q or log(rp) ?\n",
    "# NOTE this is an approximation!\n",
    "ds0_rp = df_sample[index_cols + ['year']].to_xarray().set_coords('year')\n",
    "df_sample['index'] = ds_flood_rp['index'].sel(ds0_rp, method='nearest')\n",
    "df_sample['scen'] = df_flood.reset_index().loc[df_sample['index'].values, 'scen'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ce9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_scen_unique, idxs_reverse = np.unique(df_sample['scen'], return_inverse=True)\n",
    "print(_scen_unique.size)\n",
    "flddph = da1.sel(scen=_scen_unique).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell takes some time, approx ~30 min\n",
    "# it can also be done much more intellegent accounting for the weight of each sim event based on number of occurrences\n",
    "# 0 2 5 10 25 50 100 250 500\n",
    "rps=np.array([2, 5, 10, 25, 50, 100, 250, 500])\n",
    "n = df_sample.year.max()\n",
    "cdf = np.arange(n)/n\n",
    "bins = df_sample[['year']].values.flatten()\n",
    "def _fldsrt(fld0, idxs_reverse=idxs_reverse, rp=rps, bins=bins, cdf=cdf):\n",
    "    if np.all(fld0==0):\n",
    "        return 0.0\n",
    "    fld0 = fld0[idxs_reverse] # explode unique simulations to sample size\n",
    "    df0 = pd.DataFrame(data={'fld0': fld0, 'bin':bins})\n",
    "    fld_max = df0[['fld0', 'bin']].groupby('bin').max().values.flatten() # get AM\n",
    "    fld_sorted = np.sort(fld_max) # sort AM\n",
    "    return np.interp(1-1/rp, cdf, fld_sorted)\n",
    "data=np.apply_along_axis(_fldsrt, flddph.get_axis_num(\"scen\"), np.maximum(0, flddph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodata=-999\n",
    "da_cmpnd = xr.DataArray(\n",
    "    data=data, \n",
    "    dims=('rp', 'y', 'x'),\n",
    "    coords={'rp':rps, **da1.raster.coords}\n",
    ").where(flddph.isel(scen=0)!=nodata, nodata)\n",
    "da_cmpnd.raster.set_nodata(nodata)\n",
    "da_cmpnd.raster.set_crs(da1.raster.crs)\n",
    "for rp0 in rps:\n",
    "    da_cmpnd.sel(rp=rp0).raster.to_raster(join(rdir, 'hmax', f'compound_obsdep_rp{rp0:03d}.tif'), compress='lzw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce7bfb",
   "metadata": {},
   "source": [
    "## plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df372ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
