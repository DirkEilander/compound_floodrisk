{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hydromt\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "from hydromt_sfincs import SfincsModel\n",
    "import subprocess\n",
    "import os\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d8fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulations\n",
    "rdir = r'../../4_results'\n",
    "\n",
    "scens = pd.read_csv(join(rdir, 'sim_SCEN.csv'), index_col=0).rename(columns={'h_tsw_rp': 'h_rp'})\n",
    "print(len(scens.index))\n",
    "scens.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d70ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read events\n",
    "ddir = r'../../1_data/2_forcing'\n",
    "ds_q = xr.open_dataset(join(ddir, r'cama_discharge_beira_daily_events.nc'))\n",
    "ds_q = np.maximum(ds_q, ds_q.sel(rps=0).max())\n",
    "da_h = xr.open_dataarray(join(ddir, r'reanalysis_gtsm_v1_beira_extended_events.nc'))\n",
    "da_p = xr.open_dataarray(join(ddir, r'era5_precip_beira_hourly_spatialmean_events.nc'))\n",
    "events = dict(\n",
    "    h = da_h.reset_coords(drop=True),\n",
    "    qb = ds_q['qb'].reset_coords(drop=True),\n",
    "    qp = ds_q['qp'].reset_coords(drop=True),\n",
    "    p = da_p.reset_coords(drop=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fb9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lagtimes relative to qb\n",
    "from datetime import timedelta\n",
    "lagtimes = pd.read_csv(join(rdir, 'lagtimes.csv'), index_col=0)['lag'].to_dict()\n",
    "lagtimes = {k: timedelta(days=v) for k,v in lagtimes.items()}\n",
    "lagtimes['h'] = lagtimes['s']\n",
    "lagtimes['qb'] = timedelta(days=0)\n",
    "postfix = ''\n",
    "lagtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670dd796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"worst case\" zero timelag\n",
    "# lagtimes = {key: timedelta(days=0) for key in events.keys()}\n",
    "# postfix = '_dt0'\n",
    "# lagtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df60706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydromt_sfincs.utils import parse_datetime, write_timeseries, write_inp\n",
    "\n",
    "tstart = '20200101 000000'\n",
    "tstop = '20200115 000000'\n",
    "tref = parse_datetime(tstart)\n",
    "t0 = tref + timedelta(days=7)\n",
    "\n",
    "def get_ts(dvar, rp, lagtimes=lagtimes, events=events):\n",
    "    if rp not in events[dvar].rps:\n",
    "        return\n",
    "    ts = events[dvar].sel(rps=rp).to_series()\n",
    "    ts.index += (lagtimes[dvar].total_seconds() / 3600)\n",
    "    ts.index = t0 + np.array([timedelta(hours=dt) for dt in ts.index.values])\n",
    "    dates = pd.date_range(tstart, tstop, freq=np.diff(ts.index.to_pydatetime())[0])\n",
    "    ts = ts.reindex(dates, fill_value=0)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e85645",
   "metadata": {},
   "source": [
    "## prepare simulation events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0643411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read basemodel\n",
    "mdir = r\"../../3_models/sfincs\"\n",
    "basename = '00_base_riv'\n",
    "mod0 = SfincsModel(join(mdir, basename), mode='r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select buzi and pungwe rivers\n",
    "src = mod0.forcing['dis'].vector.to_gdf().loc[[1,4],:]\n",
    "# h boundary location based on gtsm output location\n",
    "bnd = gpd.GeoDataFrame(\n",
    "    index=np.atleast_1d(da_h['stations'].values),\n",
    "    geometry=gpd.points_from_xy(\n",
    "        np.atleast_1d(da_h['station_x_coordinate'].values), \n",
    "        np.atleast_1d(da_h['station_y_coordinate'].values)\n",
    "    ),\n",
    "    crs=4326\n",
    ").to_crs(src.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd2a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify config\n",
    "config = mod0.config.copy()\n",
    "config.update({\n",
    "    'tref': tstart, \n",
    "    'tstart': tstart, \n",
    "    'tstop': tstop, \n",
    "    'outputformat': 'bin',\n",
    "    'dtmaxout': 86400,\n",
    "    'dtout': 86400,\n",
    "    'dtwnd': 600,\n",
    "    'alpha': 0.7,\n",
    "    'precipfile': 'sfincs.precip',\n",
    "    'bzsfile': 'sfincs.bzs',\n",
    "    'bndfile': 'sfincs.bnd',\n",
    "    'inifile': '../qb000_qp000_h000_p000/sfincs.zsini'\n",
    "})\n",
    "config.pop('netamprfile',None)\n",
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f68e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = ['qb_rp', 'qp_rp', 'p_rp', 'h_rp']\n",
    "scen_rps =scens[index_cols]\n",
    "scens0_lst = [scens[np.all(np.diff(scen_rps) == 0, axis=1)].sort_values('qb_rp')[1:]]\n",
    "for col in index_cols:\n",
    "    zero_cols = [c for c in index_cols if c != col]\n",
    "    scens0_lst.append(scens[np.all(scens[zero_cols]==0, axis=1)].sort_values(col)[1:])\n",
    "scens0 = pd.concat(scens0_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86225197",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, run in scens0.iterrows():\n",
    "    name = run['scen']\n",
    "    root = join(mdir, f'{name}{postfix}')\n",
    "\n",
    "    if os.path.isfile(join(root, 'sfincs.inp')): continue\n",
    "    # print(f'>>{name}')\n",
    "    # mod0 = SfincsModel(join(mdir, basename), mode='r+')\n",
    "    mod0.set_root(root, mode='w')\n",
    "    mod0._write_gis = False\n",
    "    mod0.setup_config(**config)\n",
    "    mod0.config.pop('restartfile', None)\n",
    "    if np.all(run[:4]==0):\n",
    "        mod0.setup_config(restartfile=mod0.config.pop('inifile'))\n",
    "\n",
    "    qb0 = get_ts('qb', run['qb_rp']).rename(1)\n",
    "    qp0 = get_ts('qp', run['qp_rp']).rename(4)\n",
    "    q0 = pd.concat([qb0, qp0], axis=1)\n",
    "    mod0.set_forcing_1d(ts=q0, xy=src, name='discharge')\n",
    "    \n",
    "    h0 = get_ts('h', run['h_rp']).rename(bnd.index.item()).to_frame()\n",
    "    mod0.set_forcing_1d(ts=h0, xy=bnd, name='waterlevel')\n",
    "    \n",
    "    p0 = get_ts('p', run['p_rp'])\n",
    "    if p0 is not None:\n",
    "        mod0.set_forcing_1d(ts=p0, xy=None, name='precip')\n",
    "    else:\n",
    "        mod0.forcing.pop('precip', None)\n",
    "        mod0.config.pop('precipfile')\n",
    "    \n",
    "    mod0.write_forcing()\n",
    "    mod0.write_config(rel_path=f'../{basename}')\n",
    "    \n",
    "    mod0.plot_forcing()\n",
    "    plt.close('all')\n",
    "    # mod0.plot_basemap()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7186b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38648ff479392915c1a5d77722aa6edad827edf2098e3798b9c4282ba45e9fb7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('compound_risk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
