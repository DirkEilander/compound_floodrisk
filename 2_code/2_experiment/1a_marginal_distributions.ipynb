{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b097498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f136bfa0",
   "metadata": {},
   "source": [
    "## read and align data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88119fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directory\n",
    "ddir = r'../../1_data/2_forcing'\n",
    "rdir = r\"../../4_results\"\n",
    "\n",
    "# data labels\n",
    "labels = {\n",
    "    'qb': 'Discharge Buzi\\n[m3/s]',\n",
    "    'qp': 'Discharge Pungwe\\n[m3/s]',\n",
    "    'p': 'Rainfall\\n[mm/hr]',\n",
    "    # 't': 'Tide\\n[m+MSL]',\n",
    "    's': 'Surge\\n[m]',\n",
    "    'w': 'Sign. wave height\\n[m]',\n",
    "    # 'h_ts': 'Total waterlevel\\n[m+MSL]',\n",
    "    'h_tsw': 'Total waterlevel (incl. wave setup)\\n[m+MSL]',\n",
    "    # 'ss': 'Skew surge\\n[m]',\n",
    "    # 'ssw': 'Skew surge (incl. wave setup)\\n[m]',\n",
    "    # 'sw': 'Non-tidal residual\\n[m]'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydromt\n",
    "from eva import eva_block_maxima, get_peaks, get_peak_hydrographs\n",
    "\n",
    "# discharge\n",
    "fnq = join(ddir, 'cama_discharge_beira_daily.nc')\n",
    "daq = xr.open_dataset(fnq)['discharge'].load()\n",
    "dsq = xr.merge([\n",
    "    daq.sel(index=1).rename('qb').reset_coords(drop=True),\n",
    "    daq.sel(index=4).rename('qp').reset_coords(drop=True)\n",
    "])\n",
    "# fnq = r'../../3_models/wflow/run_vito_ksath1000/output_src.nc'\n",
    "# daq = xr.open_dataset(fnq)['q_river'].load()\n",
    "# dsq = xr.merge([\n",
    "#     daq.sel(index=0).rename('qb').reset_coords(drop=True),\n",
    "#     daq.sel(index=3).rename('qp').reset_coords(drop=True)\n",
    "# ])\n",
    "\n",
    "# save qbankfull at river inflow locations of SFINCS\n",
    "dsq_eva = eva_block_maxima(\n",
    "    daq, period = 'AS-AUG', min_dist = 14,\n",
    ")\n",
    "gdf_qbf = dsq_eva['return_values'].sel(rps=2).to_dataset().vector.to_gdf().rename(columns={'return_values': 'qbankfull'})\n",
    "gdf_qbf.to_file(fnq.replace('.nc', '_qbf.geojson'), driver='GeoJSON')\n",
    "gdf_qbf['qbankfull']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc33d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTSM waterlevels + ERA5 waves\n",
    "# contains: \"waterlevel\" (tide+surge), \"tide\", \"surge\", \"shww\"\n",
    "fnh = join(ddir, 'reanalysis_gtsm_v1_beira_extended.nc')\n",
    "dsh0 = xr.open_dataset(fnh).load()\n",
    "dsh0 = dsh0.rename({'waterlevel': 'h_ts', 'surge': 's', 'tide': 't', 'shww': 'w'})\n",
    "dsh0['h_tsw'] = dsh0['h_ts'] + 0.2*dsh0['w']\n",
    "dsh0['sw'] = dsh0['s'].fillna(0) + 0.2*dsh0['w']\n",
    "# skew surge (not used)\n",
    "# high_tide = get_peaks(dsh0['t'].load(), period='12H').dropna('time').reindex_like(dsh0, 'nearest')\n",
    "# dsh0['ss'] = dsh0['h_ts'] - high_tide\n",
    "# dsh0['ssw'] = dsh0['h_tsw'] - high_tide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be459f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA5 precipitation\n",
    "fnp = join(ddir, 'era5_precip_beira_hourly_spatialmean.nc')\n",
    "dap0 = xr.open_dataset(fnp, chunks='auto')['precip'].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59daa005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample to day\n",
    "dates = pd.date_range('19800102', '20210201', freq='D')\n",
    "# dap = dap0.resample(time='1D', label='right').sum('time')\n",
    "# dsh = dsh0.resample(time='1D', label='right').max('time')\n",
    "dap = dap0.rolling(time=24, center=True, min_periods=1).mean('time').reindex(time=dates)\n",
    "dsh = dsh0.rolling(time=6*24, center=True, min_periods=1).max('time').reindex(time=dates)\n",
    "\n",
    "# merge all variables to singlge dataset\n",
    "ds = xr.merge([\n",
    "    dsq.reindex(time=dates),\n",
    "    dsh,\n",
    "    dap.rename('p')\n",
    "], compat='override').reset_coords(drop=True)#.reindex(time=dates)\n",
    "for var in ds.data_vars:\n",
    "    long_name, unit = labels[var].split('\\n')\n",
    "    ds[var].attrs.update({'long_name': long_name, 'unit': unit[1:-1]})\n",
    "ds.attrs = {}\n",
    "ds = ds[['qb', 'qp', 'p', 'h_tsw', 't', 's', 'w']]\n",
    "encoding = {var: {'zlib': True} for var in ds.data_vars}\n",
    "# ds.to_netcdf(join(ddir, 'beira_drivers_daily.nc'), encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4bae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(join(ddir, 'beira_drivers_daily.nc'))\n",
    "# ds = ds[['qb', 'qp', 'p', 'h_tsw', 't', 's', 'w']]\n",
    "drivers = [v for v in ['qb', 'qp', 'p', 's', 'w'] if v in ds]\n",
    "drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72478be3",
   "metadata": {},
   "source": [
    "## get annual maxima peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a304f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eva import get_peak_hydrographs, get_peaks\n",
    "\n",
    "# settings\n",
    "period='AS-AUG'\n",
    "\n",
    "ds_peaks = xr.Dataset(coords=ds.coords)\n",
    "for dvar in ds.data_vars.keys():\n",
    "    if dvar == 't': continue\n",
    "    ds_peaks[dvar] = get_peaks(ds[dvar], period=period, min_dist=14, min_sample_size=0)\n",
    "\n",
    "# peaks with dates\n",
    "df_peaks0 = ds_peaks.reset_coords(drop=True).dropna('time', how='all').to_dataframe()  \n",
    "\n",
    "# get maximum values within time window for non_extremes\n",
    "df_peaks0_filled = pd.DataFrame()\n",
    "ds_tmax = ds.rolling(time=7).max('time').sel(time=df_peaks0.index)\n",
    "# ds_tmax = ds.sel(time=df_peaks0.index)\n",
    "for dvar in df_peaks0.columns:\n",
    "    df_peaks0_filled[dvar] = df_peaks0[dvar].where(df_peaks0[dvar].notna(), ds_tmax[dvar])\n",
    "\n",
    "# peaks with regular spaced interval\n",
    "df_bm = df_peaks0.resample(period).max()#.dropna()\n",
    "\n",
    "# save peaks to csv\n",
    "df_peaks0.to_csv(join(rdir, 'drivers_am_peaks.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_uppercase as letters\n",
    "\n",
    "n = len(ds_peaks.data_vars)\n",
    "fig, axes = plt.subplots(n, 1, figsize=(12, 3*n), sharex=True)\n",
    "for i, dvar in enumerate(labels.keys()):\n",
    "    ds[dvar].to_series().plot(ax=axes[i], color='k')\n",
    "    df_peaks0[dvar].plot(ax=axes[i], color='r', marker='.', lw=0)\n",
    "    axes[i].set_ylabel(labels[dvar])\n",
    "    title = labels[dvar].split('\\n')[0]\n",
    "    axes[i].set_title(f'{letters[i]}) {title}')\n",
    "plt.savefig(join(r'../../4_results', f'drivers_timeseries.png'), dpi=300, bbox_axes='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88495437",
   "metadata": {},
   "source": [
    "## fit uni-variate eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc3ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eva import lmoment_fitopt, get_frozen_dist, _get_return_periods, _RPS, rps_dist, emperical_dist\n",
    "\n",
    "# prepare surge extremes\n",
    "fileS = 'Beira_STORM_surges.nc' #We look at the 3000 yr of data\n",
    "da_surge = xr.open_dataarray(join(ddir, fileS))#[-3000:]\n",
    "\n",
    "x_etc = ds_peaks['s'].dropna('time').to_series().sort_values().values[:-2]  # filter 2 TCs\n",
    "params, dist = lmoment_fitopt(x_etc, distributions=['gev', 'gumb'], criterium='AIC')\n",
    "dist_etc = get_frozen_dist(params, dist)\n",
    "\n",
    "x_tc = da_surge.values.flatten()\n",
    "dist_tc = emperical_dist(x_tc, 3000)\n",
    "\n",
    "# combine: rp(x) = 1 / (1/rp(x_TC) + 1/rp(x_ETC))\n",
    "xs = np.arange(0.1, np.max(x_tc), 0.1)\n",
    "rp_tc = 1/dist_tc.sf(xs)\n",
    "rp_etc = 1/(1-dist_etc.cdf(xs))\n",
    "rp_tot = 1/(1/rp_etc + 1/rp_tc)\n",
    "dist_surge = rps_dist(rp_tot, xs)\n",
    "\n",
    "# plot\n",
    "fgumbplot = lambda x: -np.log(-np.log(1.0 - 1.0 / x))\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(fgumbplot(_get_return_periods(x_etc)), x_etc, '.b', label='ETC')\n",
    "ax.plot(fgumbplot(_get_return_periods(x_tc, extremes_rate=x_tc.size/3000)), x_tc, '.r', label='TC')\n",
    "ax.plot(fgumbplot(rp_tot), xs, '--k', lw=2, label='combined')\n",
    "ax.set_ylabel(\"Return value\")\n",
    "ax.set_xticks(fgumbplot(_RPS))\n",
    "ax.set_xticklabels(_RPS)\n",
    "ax.set_xlabel(\"Return period\")\n",
    "ax.set_xlim([fgumbplot(1.1), fgumbplot(1000)])\n",
    "ax.grid()\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ff550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surge_emp_dist = pd.DataFrame(columns=['rp[year]', 'surge[m]'], data=np.vstack([rp_tot,xs]).T)\n",
    "df_surge_emp_dist.to_csv(join(rdir, 'marginal_surge.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6937dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read AM from stochastic event set to create the figure (this can be skipped at first iteration)\n",
    "df_sim_am0 = pd.read_csv(join(rdir, 'sim_AM.csv'), index_col=0)\n",
    "dist_htsw = emperical_dist(df_sim_am0['h_tsw'].values, df_sim_am0['h_tsw'].size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eva import lmoment_fitopt, get_frozen_dist, plot_return_values, _RPS, _get_return_values, eva_idf\n",
    "fgumbplot = lambda x: -np.log(-np.log(1.0 - 1.0 / x))\n",
    "\n",
    "n = len(ds_peaks.data_vars)\n",
    "dparams = ['shape', 'loc', 'scale']\n",
    "distributions = ['gev', 'gumb']#[1:]\n",
    "\n",
    "fig, axes = plt.subplots(n, 1, figsize=(12, 3*n), sharex=True)\n",
    "\n",
    "df_eva = pd.DataFrame(columns=['dist'] + dparams)\n",
    "df_rps = pd.DataFrame(index=np.hstack([[1.1], _RPS]))\n",
    "df_rps.index.name = 'rps'\n",
    "dists = {}\n",
    "print(df_rps)\n",
    "# use marginal distributions to transform quantiles back to normal space\n",
    "for dvar in df_eva.index:\n",
    "    params = df_eva.loc[dvar, dparams].dropna()\n",
    "    dist = df_eva.loc[dvar, 'dist']\n",
    "\n",
    "for i, dvar in enumerate(labels.keys()):\n",
    "\n",
    "    if dvar == 's':\n",
    "        dists[dvar] = dist_surge\n",
    "        df_rps[dvar] = dist_surge.ppf(1-1/df_rps.index.values)\n",
    "        axes[i].plot(fgumbplot(_get_return_periods(x_etc)), x_etc, 'xk', label='non tropical cyclones')\n",
    "        axes[i].plot(fgumbplot(_get_return_periods(x_tc, extremes_rate=x_tc.size/3000)), x_tc, '.k', label='tropical cyclones', alpha=0.5)\n",
    "        axes[i].plot(fgumbplot(rp_tot), xs, '--k', lw=2, label='combined')\n",
    "        axes[i].set_ylabel(\"Return value\")\n",
    "        axes[i].set_xticks(fgumbplot(_RPS))\n",
    "        # axes[i].set_xticklabels(_RPS)\n",
    "        # axes[i].set_xlabel(\"Return period\")\n",
    "        axes[i].grid()        \n",
    "        axes[i].legend()\n",
    "    elif dvar == 'h_tsw':\n",
    "        dists[dvar] = dist_htsw\n",
    "        df_rps[dvar] = dists['h_tsw'].ppf(1-1/df_rps.index.values)\n",
    "        axes[i].plot(fgumbplot(1/dists['h_tsw'].freq), dists['h_tsw'].data, '.k', label='stochastic event set')\n",
    "        axes[i].set_ylabel(\"Return value\")\n",
    "        axes[i].set_xticks(fgumbplot(_RPS))\n",
    "        axes[i].set_xticklabels(_RPS)\n",
    "        axes[i].set_xlabel(\"Return period [year]\")\n",
    "        axes[i].grid()        \n",
    "        axes[i].legend()\n",
    "        axes[i].set_ylim([4.5,7.5])\n",
    "    else:\n",
    "        if dvar == 'p':\n",
    "            durations=np.array([1, 2, 3, 6, 12, 24], dtype=int)\n",
    "            da_p_bm = eva_idf(dap0, durations=durations, distribution='gumb', rps=df_rps.index.values)\n",
    "            da_p_bm0 = da_p_bm.sel(duration=24)\n",
    "            x = da_p_bm0['peaks'].dropna('time').values\n",
    "            params = da_p_bm0['parameters'].values[1:]\n",
    "            dist = da_p_bm0['distribution'].item()\n",
    "        else:\n",
    "            x = ds_peaks[dvar].dropna('time').values\n",
    "            print(x.size)\n",
    "            params, dist = lmoment_fitopt(x, distributions=distributions, criterium='AIC')\n",
    "        dists[dvar] = get_frozen_dist(params, dist)\n",
    "        df_eva.loc[dvar, dparams[-len(params):]] = params\n",
    "        df_eva.loc[dvar, 'dist'] = dist\n",
    "        df_rps[dvar] = _get_return_values(params, dist, rps=df_rps.index.values)\n",
    "        _ = plot_return_values(x, params, dist, ax=axes[i])\n",
    "        axes[i].set_ylim([x.min()*0.9, axes[i].get_ylim()[1]])\n",
    "\n",
    "    axes[i].set_xlim([0.01, fgumbplot(500)])\n",
    "    title = labels[dvar].split('\\n')[0]\n",
    "    axes[i].set_title(f'{letters[i]}) {title}')\n",
    "    \n",
    "    axes[i].set_ylabel(labels[dvar])\n",
    "    if i < n-1:\n",
    "        axes[i].set_xlabel('')\n",
    "\n",
    "# save parameters\n",
    "# df_eva.to_csv(join(rdir, 'marginal_params.csv'))\n",
    "\n",
    "plt.savefig(join(r'../../4_results', f'drivers_eva.png'), dpi=300, bbox_axes='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "RPS = [2,5,10,50,100,500]\n",
    "df_rps = pd.read_csv(join(rdir, f'marginal_rps.csv'), index_col=0).rename(columns={'h_tsw':'h'})\n",
    "df_rps = df_rps.drop(columns='h_tsw0')\n",
    "df_rps['w'] = df_rps['w']*0.2\n",
    "df_rps = df_rps.loc[RPS,:].round(2)\n",
    "df_rps.to_clipboard()\n",
    "df_rps"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38648ff479392915c1a5d77722aa6edad827edf2098e3798b9c4282ba45e9fb7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('compound_risk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
